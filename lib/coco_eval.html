<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>2_pytorch_finetune.lib.coco_eval API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>2_pytorch_finetune.lib.coco_eval</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import json
import tempfile

import numpy as np
import copy
import time
import torch
import torch._six

from pycocotools.cocoeval import COCOeval
from pycocotools.coco import COCO
import pycocotools.mask as mask_util

from collections import defaultdict

import utils


class CocoEvaluator(object):
    def __init__(self, coco_gt, iou_types):
        assert isinstance(iou_types, (list, tuple))
        coco_gt = copy.deepcopy(coco_gt)
        self.coco_gt = coco_gt

        self.iou_types = iou_types
        self.coco_eval = {}
        for iou_type in iou_types:
            self.coco_eval[iou_type] = COCOeval(coco_gt, iouType=iou_type)

        self.img_ids = []
        self.eval_imgs = {k: [] for k in iou_types}
        

    def update(self, predictions):
        img_ids = list(np.unique(list(predictions.keys())))
        self.img_ids.extend(img_ids)

        for iou_type in self.iou_types:
            results = self.prepare(predictions, iou_type)
            coco_dt = loadRes(self.coco_gt, results) if results else COCO()
            coco_eval = self.coco_eval[iou_type]

            coco_eval.cocoDt = coco_dt
            coco_eval.params.imgIds = list(img_ids)
            img_ids, eval_imgs = evaluate(coco_eval)

            self.eval_imgs[iou_type].append(eval_imgs)

    def synchronize_between_processes(self):
        for iou_type in self.iou_types:
            self.eval_imgs[iou_type] = np.concatenate(self.eval_imgs[iou_type], 2)
            create_common_coco_eval(self.coco_eval[iou_type], self.img_ids, self.eval_imgs[iou_type])

    def accumulate(self):
        for coco_eval in self.coco_eval.values():
            coco_eval.accumulate()

    def summarize(self):
        for iou_type, coco_eval in self.coco_eval.items():
            print(&#34;IoU metric: {}&#34;.format(iou_type))
            coco_eval.summarize()

    def prepare(self, predictions, iou_type):
        if iou_type == &#34;bbox&#34;:
            return self.prepare_for_coco_detection(predictions)
        elif iou_type == &#34;segm&#34;:
            return self.prepare_for_coco_segmentation(predictions)
        elif iou_type == &#34;keypoints&#34;:
            return self.prepare_for_coco_keypoint(predictions)
        else:
            raise ValueError(&#34;Unknown iou type {}&#34;.format(iou_type))

    def prepare_for_coco_detection(self, predictions):
        coco_results = []
        for original_id, prediction in predictions.items():
            if len(prediction) == 0:
                continue

            boxes = prediction[&#34;boxes&#34;]
            boxes = convert_to_xywh(boxes).tolist()
            scores = prediction[&#34;scores&#34;].tolist()
            labels = prediction[&#34;labels&#34;].tolist()

            coco_results.extend(
                [
                    {
                        &#34;image_id&#34;: original_id,
                        &#34;category_id&#34;: labels[k],
                        &#34;bbox&#34;: box,
                        &#34;score&#34;: scores[k],
                    }
                    for k, box in enumerate(boxes)
                ]
            )
        return coco_results

    def prepare_for_coco_segmentation(self, predictions):
        coco_results = []
        for original_id, prediction in predictions.items():
            if len(prediction) == 0:
                continue

            scores = prediction[&#34;scores&#34;]
            labels = prediction[&#34;labels&#34;]
            masks = prediction[&#34;masks&#34;]

            masks = masks &gt; 0.5

            scores = prediction[&#34;scores&#34;].tolist()
            labels = prediction[&#34;labels&#34;].tolist()

            rles = [
                mask_util.encode(np.array(mask[0, :, :, np.newaxis], dtype=np.uint8, order=&#34;F&#34;))[0]
                for mask in masks
            ]
            for rle in rles:
                rle[&#34;counts&#34;] = rle[&#34;counts&#34;].decode(&#34;utf-8&#34;)

            coco_results.extend(
                [
                    {
                        &#34;image_id&#34;: original_id,
                        &#34;category_id&#34;: labels[k],
                        &#34;segmentation&#34;: rle,
                        &#34;score&#34;: scores[k],
                    }
                    for k, rle in enumerate(rles)
                ]
            )
        return coco_results

    def prepare_for_coco_keypoint(self, predictions):
        coco_results = []
        for original_id, prediction in predictions.items():
            if len(prediction) == 0:
                continue

            boxes = prediction[&#34;boxes&#34;]
            boxes = convert_to_xywh(boxes).tolist()
            scores = prediction[&#34;scores&#34;].tolist()
            labels = prediction[&#34;labels&#34;].tolist()
            keypoints = prediction[&#34;keypoints&#34;]
            keypoints = keypoints.flatten(start_dim=1).tolist()

            coco_results.extend(
                [
                    {
                        &#34;image_id&#34;: original_id,
                        &#34;category_id&#34;: labels[k],
                        &#39;keypoints&#39;: keypoint,
                        &#34;score&#34;: scores[k],
                    }
                    for k, keypoint in enumerate(keypoints)
                ]
            )
        return coco_results


def convert_to_xywh(boxes):
    xmin, ymin, xmax, ymax = boxes.unbind(1)
    return torch.stack((xmin, ymin, xmax - xmin, ymax - ymin), dim=1)


def merge(img_ids, eval_imgs):
    all_img_ids = utils.all_gather(img_ids)
    all_eval_imgs = utils.all_gather(eval_imgs)

    merged_img_ids = []
    for p in all_img_ids:
        merged_img_ids.extend(p)

    merged_eval_imgs = []
    for p in all_eval_imgs:
        merged_eval_imgs.append(p)

    merged_img_ids = np.array(merged_img_ids)
    merged_eval_imgs = np.concatenate(merged_eval_imgs, 2)

    # keep only unique (and in sorted order) images
    merged_img_ids, idx = np.unique(merged_img_ids, return_index=True)
    merged_eval_imgs = merged_eval_imgs[..., idx]

    return merged_img_ids, merged_eval_imgs


def create_common_coco_eval(coco_eval, img_ids, eval_imgs):
    img_ids, eval_imgs = merge(img_ids, eval_imgs)
    img_ids = list(img_ids)
    eval_imgs = list(eval_imgs.flatten())

    coco_eval.evalImgs = eval_imgs
    coco_eval.params.imgIds = img_ids
    coco_eval._paramsEval = copy.deepcopy(coco_eval.params)


#################################################################
# From pycocotools, just removed the prints and fixed
# a Python3 bug about unicode not defined
#################################################################

# Ideally, pycocotools wouldn&#39;t have hard-coded prints
# so that we could avoid copy-pasting those two functions

def createIndex(self):
    # create index
    # print(&#39;creating index...&#39;)
    anns, cats, imgs = {}, {}, {}
    imgToAnns, catToImgs = defaultdict(list), defaultdict(list)
    if &#39;annotations&#39; in self.dataset:
        for ann in self.dataset[&#39;annotations&#39;]:
            imgToAnns[ann[&#39;image_id&#39;]].append(ann)
            anns[ann[&#39;id&#39;]] = ann

    if &#39;images&#39; in self.dataset:
        for img in self.dataset[&#39;images&#39;]:
            imgs[img[&#39;id&#39;]] = img

    if &#39;categories&#39; in self.dataset:
        for cat in self.dataset[&#39;categories&#39;]:
            cats[cat[&#39;id&#39;]] = cat

    if &#39;annotations&#39; in self.dataset and &#39;categories&#39; in self.dataset:
        for ann in self.dataset[&#39;annotations&#39;]:
            catToImgs[ann[&#39;category_id&#39;]].append(ann[&#39;image_id&#39;])

    # print(&#39;index created!&#39;)

    # create class members
    self.anns = anns
    self.imgToAnns = imgToAnns
    self.catToImgs = catToImgs
    self.imgs = imgs
    self.cats = cats


maskUtils = mask_util


def loadRes(self, resFile):
    &#34;&#34;&#34;
    Load result file and return a result api object.
    :param   resFile (str)     : file name of result file
    :return: res (obj)         : result api object
    &#34;&#34;&#34;
    res = COCO()
    res.dataset[&#39;images&#39;] = [img for img in self.dataset[&#39;images&#39;]]

    # print(&#39;Loading and preparing results...&#39;)
    # tic = time.time()
    if isinstance(resFile, torch._six.string_classes):
        anns = json.load(open(resFile))
    elif type(resFile) == np.ndarray:
        anns = self.loadNumpyAnnotations(resFile)
    else:
        anns = resFile
    assert type(anns) == list, &#39;results in not an array of objects&#39;
    annsImgIds = [ann[&#39;image_id&#39;] for ann in anns]
    assert set(annsImgIds) == (set(annsImgIds) &amp; set(self.getImgIds())), \
        &#39;Results do not correspond to current coco set&#39;
    if &#39;caption&#39; in anns[0]:
        imgIds = set([img[&#39;id&#39;] for img in res.dataset[&#39;images&#39;]]) &amp; set([ann[&#39;image_id&#39;] for ann in anns])
        res.dataset[&#39;images&#39;] = [img for img in res.dataset[&#39;images&#39;] if img[&#39;id&#39;] in imgIds]
        for id, ann in enumerate(anns):
            ann[&#39;id&#39;] = id + 1
    elif &#39;bbox&#39; in anns[0] and not anns[0][&#39;bbox&#39;] == []:
        res.dataset[&#39;categories&#39;] = copy.deepcopy(self.dataset[&#39;categories&#39;])
        for id, ann in enumerate(anns):
            bb = ann[&#39;bbox&#39;]
            x1, x2, y1, y2 = [bb[0], bb[0] + bb[2], bb[1], bb[1] + bb[3]]
            if &#39;segmentation&#39; not in ann:
                ann[&#39;segmentation&#39;] = [[x1, y1, x1, y2, x2, y2, x2, y1]]
            ann[&#39;area&#39;] = bb[2] * bb[3]
            ann[&#39;id&#39;] = id + 1
            ann[&#39;iscrowd&#39;] = 0
    elif &#39;segmentation&#39; in anns[0]:
        res.dataset[&#39;categories&#39;] = copy.deepcopy(self.dataset[&#39;categories&#39;])
        for id, ann in enumerate(anns):
            # now only support compressed RLE format as segmentation results
            ann[&#39;area&#39;] = maskUtils.area(ann[&#39;segmentation&#39;])
            if &#39;bbox&#39; not in ann:
                ann[&#39;bbox&#39;] = maskUtils.toBbox(ann[&#39;segmentation&#39;])
            ann[&#39;id&#39;] = id + 1
            ann[&#39;iscrowd&#39;] = 0
    elif &#39;keypoints&#39; in anns[0]:
        res.dataset[&#39;categories&#39;] = copy.deepcopy(self.dataset[&#39;categories&#39;])
        for id, ann in enumerate(anns):
            s = ann[&#39;keypoints&#39;]
            x = s[0::3]
            y = s[1::3]
            x1, x2, y1, y2 = np.min(x), np.max(x), np.min(y), np.max(y)
            ann[&#39;area&#39;] = (x2 - x1) * (y2 - y1)
            ann[&#39;id&#39;] = id + 1
            ann[&#39;bbox&#39;] = [x1, y1, x2 - x1, y2 - y1]
    # print(&#39;DONE (t={:0.2f}s)&#39;.format(time.time()- tic))

    res.dataset[&#39;annotations&#39;] = anns
    createIndex(res)
    return res


def evaluate(self):
    &#39;&#39;&#39;
    Run per image evaluation on given images and store results (a list of dict) in self.evalImgs
    :return: None
    &#39;&#39;&#39;
    # tic = time.time()
    # print(&#39;Running per image evaluation...&#39;)
    p = self.params
    # add backward compatibility if useSegm is specified in params
    if p.useSegm is not None:
        p.iouType = &#39;segm&#39; if p.useSegm == 1 else &#39;bbox&#39;
        print(&#39;useSegm (deprecated) is not None. Running {} evaluation&#39;.format(p.iouType))
    # print(&#39;Evaluate annotation type *{}*&#39;.format(p.iouType))
    p.imgIds = list(np.unique(p.imgIds))
    if p.useCats:
        p.catIds = list(np.unique(p.catIds))
    p.maxDets = sorted(p.maxDets)
    self.params = p

    self._prepare()
    # loop through images, area range, max detection number
    catIds = p.catIds if p.useCats else [-1]

    if p.iouType == &#39;segm&#39; or p.iouType == &#39;bbox&#39;:
        computeIoU = self.computeIoU
    elif p.iouType == &#39;keypoints&#39;:
        computeIoU = self.computeOks
    self.ious = {
        (imgId, catId): computeIoU(imgId, catId)
        for imgId in p.imgIds
        for catId in catIds}

    evaluateImg = self.evaluateImg
    maxDet = p.maxDets[-1]
    evalImgs = [
        evaluateImg(imgId, catId, areaRng, maxDet)
        for catId in catIds
        for areaRng in p.areaRng
        for imgId in p.imgIds
    ]
    # this is NOT in the pycocotools code, but could be done outside
    evalImgs = np.asarray(evalImgs).reshape(len(catIds), len(p.areaRng), len(p.imgIds))
    self._paramsEval = copy.deepcopy(self.params)
    # toc = time.time()
    # print(&#39;DONE (t={:0.2f}s).&#39;.format(toc-tic))
    return p.imgIds, evalImgs

#################################################################
# end of straight copy from pycocotools, just removing the prints
#################################################################</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="2_pytorch_finetune.lib.coco_eval.convert_to_xywh"><code class="name flex">
<span>def <span class="ident">convert_to_xywh</span></span>(<span>boxes)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_to_xywh(boxes):
    xmin, ymin, xmax, ymax = boxes.unbind(1)
    return torch.stack((xmin, ymin, xmax - xmin, ymax - ymin), dim=1)</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.createIndex"><code class="name flex">
<span>def <span class="ident">createIndex</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def createIndex(self):
    # create index
    # print(&#39;creating index...&#39;)
    anns, cats, imgs = {}, {}, {}
    imgToAnns, catToImgs = defaultdict(list), defaultdict(list)
    if &#39;annotations&#39; in self.dataset:
        for ann in self.dataset[&#39;annotations&#39;]:
            imgToAnns[ann[&#39;image_id&#39;]].append(ann)
            anns[ann[&#39;id&#39;]] = ann

    if &#39;images&#39; in self.dataset:
        for img in self.dataset[&#39;images&#39;]:
            imgs[img[&#39;id&#39;]] = img

    if &#39;categories&#39; in self.dataset:
        for cat in self.dataset[&#39;categories&#39;]:
            cats[cat[&#39;id&#39;]] = cat

    if &#39;annotations&#39; in self.dataset and &#39;categories&#39; in self.dataset:
        for ann in self.dataset[&#39;annotations&#39;]:
            catToImgs[ann[&#39;category_id&#39;]].append(ann[&#39;image_id&#39;])

    # print(&#39;index created!&#39;)

    # create class members
    self.anns = anns
    self.imgToAnns = imgToAnns
    self.catToImgs = catToImgs
    self.imgs = imgs
    self.cats = cats</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.create_common_coco_eval"><code class="name flex">
<span>def <span class="ident">create_common_coco_eval</span></span>(<span>coco_eval, img_ids, eval_imgs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_common_coco_eval(coco_eval, img_ids, eval_imgs):
    img_ids, eval_imgs = merge(img_ids, eval_imgs)
    img_ids = list(img_ids)
    eval_imgs = list(eval_imgs.flatten())

    coco_eval.evalImgs = eval_imgs
    coco_eval.params.imgIds = img_ids
    coco_eval._paramsEval = copy.deepcopy(coco_eval.params)</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Run per image evaluation on given images and store results (a list of dict) in self.evalImgs
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self):
    &#39;&#39;&#39;
    Run per image evaluation on given images and store results (a list of dict) in self.evalImgs
    :return: None
    &#39;&#39;&#39;
    # tic = time.time()
    # print(&#39;Running per image evaluation...&#39;)
    p = self.params
    # add backward compatibility if useSegm is specified in params
    if p.useSegm is not None:
        p.iouType = &#39;segm&#39; if p.useSegm == 1 else &#39;bbox&#39;
        print(&#39;useSegm (deprecated) is not None. Running {} evaluation&#39;.format(p.iouType))
    # print(&#39;Evaluate annotation type *{}*&#39;.format(p.iouType))
    p.imgIds = list(np.unique(p.imgIds))
    if p.useCats:
        p.catIds = list(np.unique(p.catIds))
    p.maxDets = sorted(p.maxDets)
    self.params = p

    self._prepare()
    # loop through images, area range, max detection number
    catIds = p.catIds if p.useCats else [-1]

    if p.iouType == &#39;segm&#39; or p.iouType == &#39;bbox&#39;:
        computeIoU = self.computeIoU
    elif p.iouType == &#39;keypoints&#39;:
        computeIoU = self.computeOks
    self.ious = {
        (imgId, catId): computeIoU(imgId, catId)
        for imgId in p.imgIds
        for catId in catIds}

    evaluateImg = self.evaluateImg
    maxDet = p.maxDets[-1]
    evalImgs = [
        evaluateImg(imgId, catId, areaRng, maxDet)
        for catId in catIds
        for areaRng in p.areaRng
        for imgId in p.imgIds
    ]
    # this is NOT in the pycocotools code, but could be done outside
    evalImgs = np.asarray(evalImgs).reshape(len(catIds), len(p.areaRng), len(p.imgIds))
    self._paramsEval = copy.deepcopy(self.params)
    # toc = time.time()
    # print(&#39;DONE (t={:0.2f}s).&#39;.format(toc-tic))
    return p.imgIds, evalImgs</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.loadRes"><code class="name flex">
<span>def <span class="ident">loadRes</span></span>(<span>self, resFile)</span>
</code></dt>
<dd>
<div class="desc"><p>Load result file and return a result api object.
:param
resFile (str)
: file name of result file
:return: res (obj)
: result api object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def loadRes(self, resFile):
    &#34;&#34;&#34;
    Load result file and return a result api object.
    :param   resFile (str)     : file name of result file
    :return: res (obj)         : result api object
    &#34;&#34;&#34;
    res = COCO()
    res.dataset[&#39;images&#39;] = [img for img in self.dataset[&#39;images&#39;]]

    # print(&#39;Loading and preparing results...&#39;)
    # tic = time.time()
    if isinstance(resFile, torch._six.string_classes):
        anns = json.load(open(resFile))
    elif type(resFile) == np.ndarray:
        anns = self.loadNumpyAnnotations(resFile)
    else:
        anns = resFile
    assert type(anns) == list, &#39;results in not an array of objects&#39;
    annsImgIds = [ann[&#39;image_id&#39;] for ann in anns]
    assert set(annsImgIds) == (set(annsImgIds) &amp; set(self.getImgIds())), \
        &#39;Results do not correspond to current coco set&#39;
    if &#39;caption&#39; in anns[0]:
        imgIds = set([img[&#39;id&#39;] for img in res.dataset[&#39;images&#39;]]) &amp; set([ann[&#39;image_id&#39;] for ann in anns])
        res.dataset[&#39;images&#39;] = [img for img in res.dataset[&#39;images&#39;] if img[&#39;id&#39;] in imgIds]
        for id, ann in enumerate(anns):
            ann[&#39;id&#39;] = id + 1
    elif &#39;bbox&#39; in anns[0] and not anns[0][&#39;bbox&#39;] == []:
        res.dataset[&#39;categories&#39;] = copy.deepcopy(self.dataset[&#39;categories&#39;])
        for id, ann in enumerate(anns):
            bb = ann[&#39;bbox&#39;]
            x1, x2, y1, y2 = [bb[0], bb[0] + bb[2], bb[1], bb[1] + bb[3]]
            if &#39;segmentation&#39; not in ann:
                ann[&#39;segmentation&#39;] = [[x1, y1, x1, y2, x2, y2, x2, y1]]
            ann[&#39;area&#39;] = bb[2] * bb[3]
            ann[&#39;id&#39;] = id + 1
            ann[&#39;iscrowd&#39;] = 0
    elif &#39;segmentation&#39; in anns[0]:
        res.dataset[&#39;categories&#39;] = copy.deepcopy(self.dataset[&#39;categories&#39;])
        for id, ann in enumerate(anns):
            # now only support compressed RLE format as segmentation results
            ann[&#39;area&#39;] = maskUtils.area(ann[&#39;segmentation&#39;])
            if &#39;bbox&#39; not in ann:
                ann[&#39;bbox&#39;] = maskUtils.toBbox(ann[&#39;segmentation&#39;])
            ann[&#39;id&#39;] = id + 1
            ann[&#39;iscrowd&#39;] = 0
    elif &#39;keypoints&#39; in anns[0]:
        res.dataset[&#39;categories&#39;] = copy.deepcopy(self.dataset[&#39;categories&#39;])
        for id, ann in enumerate(anns):
            s = ann[&#39;keypoints&#39;]
            x = s[0::3]
            y = s[1::3]
            x1, x2, y1, y2 = np.min(x), np.max(x), np.min(y), np.max(y)
            ann[&#39;area&#39;] = (x2 - x1) * (y2 - y1)
            ann[&#39;id&#39;] = id + 1
            ann[&#39;bbox&#39;] = [x1, y1, x2 - x1, y2 - y1]
    # print(&#39;DONE (t={:0.2f}s)&#39;.format(time.time()- tic))

    res.dataset[&#39;annotations&#39;] = anns
    createIndex(res)
    return res</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.merge"><code class="name flex">
<span>def <span class="ident">merge</span></span>(<span>img_ids, eval_imgs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge(img_ids, eval_imgs):
    all_img_ids = utils.all_gather(img_ids)
    all_eval_imgs = utils.all_gather(eval_imgs)

    merged_img_ids = []
    for p in all_img_ids:
        merged_img_ids.extend(p)

    merged_eval_imgs = []
    for p in all_eval_imgs:
        merged_eval_imgs.append(p)

    merged_img_ids = np.array(merged_img_ids)
    merged_eval_imgs = np.concatenate(merged_eval_imgs, 2)

    # keep only unique (and in sorted order) images
    merged_img_ids, idx = np.unique(merged_img_ids, return_index=True)
    merged_eval_imgs = merged_eval_imgs[..., idx]

    return merged_img_ids, merged_eval_imgs</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="2_pytorch_finetune.lib.coco_eval.CocoEvaluator"><code class="flex name class">
<span>class <span class="ident">CocoEvaluator</span></span>
<span>(</span><span>coco_gt, iou_types)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CocoEvaluator(object):
    def __init__(self, coco_gt, iou_types):
        assert isinstance(iou_types, (list, tuple))
        coco_gt = copy.deepcopy(coco_gt)
        self.coco_gt = coco_gt

        self.iou_types = iou_types
        self.coco_eval = {}
        for iou_type in iou_types:
            self.coco_eval[iou_type] = COCOeval(coco_gt, iouType=iou_type)

        self.img_ids = []
        self.eval_imgs = {k: [] for k in iou_types}
        

    def update(self, predictions):
        img_ids = list(np.unique(list(predictions.keys())))
        self.img_ids.extend(img_ids)

        for iou_type in self.iou_types:
            results = self.prepare(predictions, iou_type)
            coco_dt = loadRes(self.coco_gt, results) if results else COCO()
            coco_eval = self.coco_eval[iou_type]

            coco_eval.cocoDt = coco_dt
            coco_eval.params.imgIds = list(img_ids)
            img_ids, eval_imgs = evaluate(coco_eval)

            self.eval_imgs[iou_type].append(eval_imgs)

    def synchronize_between_processes(self):
        for iou_type in self.iou_types:
            self.eval_imgs[iou_type] = np.concatenate(self.eval_imgs[iou_type], 2)
            create_common_coco_eval(self.coco_eval[iou_type], self.img_ids, self.eval_imgs[iou_type])

    def accumulate(self):
        for coco_eval in self.coco_eval.values():
            coco_eval.accumulate()

    def summarize(self):
        for iou_type, coco_eval in self.coco_eval.items():
            print(&#34;IoU metric: {}&#34;.format(iou_type))
            coco_eval.summarize()

    def prepare(self, predictions, iou_type):
        if iou_type == &#34;bbox&#34;:
            return self.prepare_for_coco_detection(predictions)
        elif iou_type == &#34;segm&#34;:
            return self.prepare_for_coco_segmentation(predictions)
        elif iou_type == &#34;keypoints&#34;:
            return self.prepare_for_coco_keypoint(predictions)
        else:
            raise ValueError(&#34;Unknown iou type {}&#34;.format(iou_type))

    def prepare_for_coco_detection(self, predictions):
        coco_results = []
        for original_id, prediction in predictions.items():
            if len(prediction) == 0:
                continue

            boxes = prediction[&#34;boxes&#34;]
            boxes = convert_to_xywh(boxes).tolist()
            scores = prediction[&#34;scores&#34;].tolist()
            labels = prediction[&#34;labels&#34;].tolist()

            coco_results.extend(
                [
                    {
                        &#34;image_id&#34;: original_id,
                        &#34;category_id&#34;: labels[k],
                        &#34;bbox&#34;: box,
                        &#34;score&#34;: scores[k],
                    }
                    for k, box in enumerate(boxes)
                ]
            )
        return coco_results

    def prepare_for_coco_segmentation(self, predictions):
        coco_results = []
        for original_id, prediction in predictions.items():
            if len(prediction) == 0:
                continue

            scores = prediction[&#34;scores&#34;]
            labels = prediction[&#34;labels&#34;]
            masks = prediction[&#34;masks&#34;]

            masks = masks &gt; 0.5

            scores = prediction[&#34;scores&#34;].tolist()
            labels = prediction[&#34;labels&#34;].tolist()

            rles = [
                mask_util.encode(np.array(mask[0, :, :, np.newaxis], dtype=np.uint8, order=&#34;F&#34;))[0]
                for mask in masks
            ]
            for rle in rles:
                rle[&#34;counts&#34;] = rle[&#34;counts&#34;].decode(&#34;utf-8&#34;)

            coco_results.extend(
                [
                    {
                        &#34;image_id&#34;: original_id,
                        &#34;category_id&#34;: labels[k],
                        &#34;segmentation&#34;: rle,
                        &#34;score&#34;: scores[k],
                    }
                    for k, rle in enumerate(rles)
                ]
            )
        return coco_results

    def prepare_for_coco_keypoint(self, predictions):
        coco_results = []
        for original_id, prediction in predictions.items():
            if len(prediction) == 0:
                continue

            boxes = prediction[&#34;boxes&#34;]
            boxes = convert_to_xywh(boxes).tolist()
            scores = prediction[&#34;scores&#34;].tolist()
            labels = prediction[&#34;labels&#34;].tolist()
            keypoints = prediction[&#34;keypoints&#34;]
            keypoints = keypoints.flatten(start_dim=1).tolist()

            coco_results.extend(
                [
                    {
                        &#34;image_id&#34;: original_id,
                        &#34;category_id&#34;: labels[k],
                        &#39;keypoints&#39;: keypoint,
                        &#34;score&#34;: scores[k],
                    }
                    for k, keypoint in enumerate(keypoints)
                ]
            )
        return coco_results</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.accumulate"><code class="name flex">
<span>def <span class="ident">accumulate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def accumulate(self):
    for coco_eval in self.coco_eval.values():
        coco_eval.accumulate()</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare"><code class="name flex">
<span>def <span class="ident">prepare</span></span>(<span>self, predictions, iou_type)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare(self, predictions, iou_type):
    if iou_type == &#34;bbox&#34;:
        return self.prepare_for_coco_detection(predictions)
    elif iou_type == &#34;segm&#34;:
        return self.prepare_for_coco_segmentation(predictions)
    elif iou_type == &#34;keypoints&#34;:
        return self.prepare_for_coco_keypoint(predictions)
    else:
        raise ValueError(&#34;Unknown iou type {}&#34;.format(iou_type))</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare_for_coco_detection"><code class="name flex">
<span>def <span class="ident">prepare_for_coco_detection</span></span>(<span>self, predictions)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_for_coco_detection(self, predictions):
    coco_results = []
    for original_id, prediction in predictions.items():
        if len(prediction) == 0:
            continue

        boxes = prediction[&#34;boxes&#34;]
        boxes = convert_to_xywh(boxes).tolist()
        scores = prediction[&#34;scores&#34;].tolist()
        labels = prediction[&#34;labels&#34;].tolist()

        coco_results.extend(
            [
                {
                    &#34;image_id&#34;: original_id,
                    &#34;category_id&#34;: labels[k],
                    &#34;bbox&#34;: box,
                    &#34;score&#34;: scores[k],
                }
                for k, box in enumerate(boxes)
            ]
        )
    return coco_results</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare_for_coco_keypoint"><code class="name flex">
<span>def <span class="ident">prepare_for_coco_keypoint</span></span>(<span>self, predictions)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_for_coco_keypoint(self, predictions):
    coco_results = []
    for original_id, prediction in predictions.items():
        if len(prediction) == 0:
            continue

        boxes = prediction[&#34;boxes&#34;]
        boxes = convert_to_xywh(boxes).tolist()
        scores = prediction[&#34;scores&#34;].tolist()
        labels = prediction[&#34;labels&#34;].tolist()
        keypoints = prediction[&#34;keypoints&#34;]
        keypoints = keypoints.flatten(start_dim=1).tolist()

        coco_results.extend(
            [
                {
                    &#34;image_id&#34;: original_id,
                    &#34;category_id&#34;: labels[k],
                    &#39;keypoints&#39;: keypoint,
                    &#34;score&#34;: scores[k],
                }
                for k, keypoint in enumerate(keypoints)
            ]
        )
    return coco_results</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare_for_coco_segmentation"><code class="name flex">
<span>def <span class="ident">prepare_for_coco_segmentation</span></span>(<span>self, predictions)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_for_coco_segmentation(self, predictions):
    coco_results = []
    for original_id, prediction in predictions.items():
        if len(prediction) == 0:
            continue

        scores = prediction[&#34;scores&#34;]
        labels = prediction[&#34;labels&#34;]
        masks = prediction[&#34;masks&#34;]

        masks = masks &gt; 0.5

        scores = prediction[&#34;scores&#34;].tolist()
        labels = prediction[&#34;labels&#34;].tolist()

        rles = [
            mask_util.encode(np.array(mask[0, :, :, np.newaxis], dtype=np.uint8, order=&#34;F&#34;))[0]
            for mask in masks
        ]
        for rle in rles:
            rle[&#34;counts&#34;] = rle[&#34;counts&#34;].decode(&#34;utf-8&#34;)

        coco_results.extend(
            [
                {
                    &#34;image_id&#34;: original_id,
                    &#34;category_id&#34;: labels[k],
                    &#34;segmentation&#34;: rle,
                    &#34;score&#34;: scores[k],
                }
                for k, rle in enumerate(rles)
            ]
        )
    return coco_results</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.summarize"><code class="name flex">
<span>def <span class="ident">summarize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def summarize(self):
    for iou_type, coco_eval in self.coco_eval.items():
        print(&#34;IoU metric: {}&#34;.format(iou_type))
        coco_eval.summarize()</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.synchronize_between_processes"><code class="name flex">
<span>def <span class="ident">synchronize_between_processes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def synchronize_between_processes(self):
    for iou_type in self.iou_types:
        self.eval_imgs[iou_type] = np.concatenate(self.eval_imgs[iou_type], 2)
        create_common_coco_eval(self.coco_eval[iou_type], self.img_ids, self.eval_imgs[iou_type])</code></pre>
</details>
</dd>
<dt id="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, predictions)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self, predictions):
    img_ids = list(np.unique(list(predictions.keys())))
    self.img_ids.extend(img_ids)

    for iou_type in self.iou_types:
        results = self.prepare(predictions, iou_type)
        coco_dt = loadRes(self.coco_gt, results) if results else COCO()
        coco_eval = self.coco_eval[iou_type]

        coco_eval.cocoDt = coco_dt
        coco_eval.params.imgIds = list(img_ids)
        img_ids, eval_imgs = evaluate(coco_eval)

        self.eval_imgs[iou_type].append(eval_imgs)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="2_pytorch_finetune.lib" href="index.html">2_pytorch_finetune.lib</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="2_pytorch_finetune.lib.coco_eval.convert_to_xywh" href="#2_pytorch_finetune.lib.coco_eval.convert_to_xywh">convert_to_xywh</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.createIndex" href="#2_pytorch_finetune.lib.coco_eval.createIndex">createIndex</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.create_common_coco_eval" href="#2_pytorch_finetune.lib.coco_eval.create_common_coco_eval">create_common_coco_eval</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.evaluate" href="#2_pytorch_finetune.lib.coco_eval.evaluate">evaluate</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.loadRes" href="#2_pytorch_finetune.lib.coco_eval.loadRes">loadRes</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.merge" href="#2_pytorch_finetune.lib.coco_eval.merge">merge</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="2_pytorch_finetune.lib.coco_eval.CocoEvaluator" href="#2_pytorch_finetune.lib.coco_eval.CocoEvaluator">CocoEvaluator</a></code></h4>
<ul class="">
<li><code><a title="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.accumulate" href="#2_pytorch_finetune.lib.coco_eval.CocoEvaluator.accumulate">accumulate</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare" href="#2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare">prepare</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare_for_coco_detection" href="#2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare_for_coco_detection">prepare_for_coco_detection</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare_for_coco_keypoint" href="#2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare_for_coco_keypoint">prepare_for_coco_keypoint</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare_for_coco_segmentation" href="#2_pytorch_finetune.lib.coco_eval.CocoEvaluator.prepare_for_coco_segmentation">prepare_for_coco_segmentation</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.summarize" href="#2_pytorch_finetune.lib.coco_eval.CocoEvaluator.summarize">summarize</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.synchronize_between_processes" href="#2_pytorch_finetune.lib.coco_eval.CocoEvaluator.synchronize_between_processes">synchronize_between_processes</a></code></li>
<li><code><a title="2_pytorch_finetune.lib.coco_eval.CocoEvaluator.update" href="#2_pytorch_finetune.lib.coco_eval.CocoEvaluator.update">update</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>